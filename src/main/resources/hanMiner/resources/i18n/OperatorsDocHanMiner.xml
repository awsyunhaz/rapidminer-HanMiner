<?xml version="1.0" encoding="windows-1252" standalone="no"?>
<operatorHelp lang="en_EN">
    <!--  This is an example how to specify the translation of operator keys to names. -->
    <operator>
        <key>read_document</key>
        <name>Read Document</name>
        <synopsis>This operator reads documents.</synopsis>
        <help>This operator can be used to create an document set. Users can either load
            text from local files or create it in a text editor. Each line of the text is
            taken as an document. Empty lines will be removed.</help>
    </operator>
    <operator>
        <key>write_document</key>
        <name>Write Document</name>
        <synopsis>This operator writes documents to file.</synopsis>
        <help>This operator writes only documents to file. Use "Write CSV" instead to write
            example set to file.</help>
    </operator>
    <operator>
        <key>tokenize</key>
        <name>Tokenize</name>
        <synopsis>This operator segments Chinese documents into words (tokens).</synopsis>
        <help> This operator segments Chinese documents into words (tokens). Users can choose
            a Standard HMM tokenizer or a high speed tokenizer (3x speed but less accuracy).</help>
    </operator>
    <operator>
        <key>filter_stopwords</key>
        <name>Filter Stopwords</name>
        <synopsis>This operator filters stopwords in text.</synopsis>
        <help>This operator can be used to remove stopwords in text. Tokens must be separated
            by one or more whitespaces. Users can either use default stopwords dictionary, or
            load custom stopwords from file.</help>
    </operator>
    <operator>
        <key>filter_tokens</key>
        <name>Filter Tokens</name>
        <synopsis>This operator filters tokens in text.</synopsis>
        <help>This operator filters tokens in text. Only tokens matches the condition will be
            removed.</help>
    </operator>
    <operator>
        <key>filter_documents</key>
        <name>Filter Documents</name>
        <synopsis>This operator filters documents by conditions.</synopsis>
        <help>This operator filters documents by conditions. Only documents match the condition
            will be removed.</help>
    </operator>
    <operator>
        <key>word_count</key>
        <name>Word Count</name>
        <synopsis>This operator counts word occurrence and frequency in texts.</synopsis>
        <help>This operator counts word occurrence and frequency in texts. The tokens
            must be separated by one or more white spaces.</help>
    </operator>
    <operator>
        <key>word_count</key>
        <name>Word Count</name>
        <synopsis>This operator computes word occurrence and frequency in texts.</synopsis>
        <help>This operator computes word occurrence and frequency in texts. Tokens
            must be separated by one or more white spaces.</help>
    </operator>
    <operator>
        <key>keyword_extraction</key>
        <name>Keyword Extraction</name>
        <synopsis>This operator extracts keywords from document using TextRank.</synopsis>
        <help>This operator extracts keywords from document using TextRank. Users can specify
            number of keywords to extract.</help>
    </operator>
    <operator>
        <key>count_vectorizer</key>
        <name>Count Vectorizer</name>
        <synopsis>This operator transforms documents into vectors using word count.</synopsis>
        <help>This operator transforms documents into vectors using word count. Tokens must be
            separated by one or more white spaces. The output is an n*m example set (n: number
            of documents, m: number of features). The result can be fed into next-step NLP models.</help>
    </operator>
    <operator>
        <key>tfidf_vectorizer</key>
        <name>TfIdf Vectorizer</name>
        <synopsis>This operator transform documents into vectors using TF-IDF.</synopsis>
        <help>This operator transforms documents into vectors using TF-IDF. Tokens must be
            separated by one or more white spaces. The output is an n*m example set (n: number
            of documents, m: number of features). The result can be fed into next-step NLP models.</help>
    </operator>
    <operator>
        <key>doc2vec</key>
        <name>Doc2vec</name>
        <synopsis>This operator transform documents into vectors using Doc2vec.</synopsis>
        <help>This operator transform documents into vectors using Doc2vec. Tokens must be
            separated by one or more white spaces. Users can either load existing model or
            train a new model with default or custom corpus.
            It can take a few minutes to train a new model at the first time. After training
            is completed, the model will be cached, so that the performance will be much
            faster if users want models with the same embedding size next time.
            The output is an n*m example set (n: number of documents, m: embedding size).
            The result can be fed into next-step NLP models.</help>
    </operator>
    <operator>
        <key>simplified_to_traditional</key>
        <name>Simplified to Traditional Chinese</name>
        <synopsis>This operator transforms simplified Chinese to traditional Chinese.</synopsis>
        <help>This operator transforms simplified Chinese to traditional Chinese.</help>
    </operator>
    <operator>
        <key>traditional_to_simplified</key>
        <name>Traditional to Simplified Chinese</name>
        <synopsis>This operator transforms traditional Chinese to simplified Chinese.</synopsis>
        <help>This operator transforms traditional Chinese to simplified Chinese.</help>
    </operator>
    <operator>
        <key>sentiment_analysis</key>
        <name>Sentiment Analysis</name>
        <synopsis>This operator classifies documents according to positive/negative sentiments.</synopsis>
        <help>This operator classifies documents according to positive/negative sentiments using a Naive Bayes
            classifier. Users can either load a pretrained model or use the default model trained on Weibo
            sentiment dataset (120k):
            https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_senti_100k/intro.ipynb.
            To train a new model, users can load a custom corpus from file. The output is an example set that
            contains both original documents and he result of classification.</help>
    </operator>
    <operator>
        <key>document_classification</key>
        <name>Document Classification</name>
        <synopsis>This operator classifies documents according to topics.</synopsis>
        <help>This operator classifies documents according to topics using a Naive Bayes classifier.
            Users can either load a pretrained model or use the default model trained on mini-Sogou news
            dataset(12k, 8 categories). To train a new model, users can load a custom corpus from file.
            The output is an example set that contains both original documents and he result of classification.</help>
    </operator>
    <operator>
        <key>part_of_speech_tagging</key>
        <name>Part-of-speech Tagging</name>
        <synopsis>This operator performs part-of-speech (POS) tagging.</synopsis>
        <help> This operator performs part-of-speech (POS) tagging. Please see the meaning of
            each tag on: http://www.hankcs.com/nlp/part-of-speech-tagging.html#h2-8</help>
    </operator>
    <operator>
        <key>entity_recognition</key>
        <name>Entity Recognition</name>
        <synopsis>This operator recognize Chinese name/place/organization entities in text.</synopsis>
        <help>This operator recognize Chinese name/place/organization entities in text. Only the
            entities will be kept in the output.</help>
    </operator>
    <operator>
        <key>dependency_parsing</key>
        <name>Dependency Parsing</name>
        <synopsis>This operator parse dependencies among words within a sentence.</synopsis>
        <help>This operator parse dependencies among words within a sentence. Sentences must be
            separated by Chinese period sign.</help>
    </operator>

    <!-- This is how group keys are translated: -->
    <group>
        <key>data</key>
        <name>Data</name>
    </group>
    <group>
        <key>processing</key>
        <name>Processing</name>
    </group>
    <group>
        <key>processing.filtering</key>
        <name>Filtering</name>
    </group>
    <group>
        <key>feature_extraction</key>
        <name>Feature Extraction</name>
    </group>
    <group>
        <key>featureExtraction.vectorizer</key>
        <name>Vectorizer</name>
    </group>
    <group>
        <key>translation</key>
        <name>Translation</name>
    </group>
    <group>
        <key>classification</key>
        <name>Classification</name>
    </group>
    <group>
        <key>analyzing</key>
        <name>Analyzing</name>
    </group>

</operatorHelp>
